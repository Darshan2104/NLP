{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnn1_DUtClRX"
   },
   "source": [
    "## Load these models and check embedding simmilarity for normal hindi, english and hinglish\n",
    "  - bert-base-multilingual-uncased\n",
    "  - xlm-roberta-base\n",
    "  - MuRil (for embedding simmilarity)\n",
    "\n",
    "##  Check if bert-base-multilingual-uncased can handle multilingual two languages in the same bot\n",
    "##  Check if xlm-roberta-base satisfies following conditions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKOBnEflCe42",
    "outputId": "ac1e9a83-1277-492f-f578-db312129d165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tokenizers\n",
    "!pip install sentencepiece\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qlmMBXpQKblj"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VWpOaTxoEizX"
   },
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "model_name_1 = \"bert-base-multilingual-uncased\"\n",
    "model_name_2 = \"xlm-roberta-base\"\n",
    "model_name_3 = \"google/muril-large-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Zb2SHHCEYF3"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "1a18c172b2c24287831febee093165c7",
      "beb414f7abc040fcbb8294bce4219f37",
      "e6744ce2795348709298aa0f1a4e2be5",
      "1a70fc6b951b4b0e92cfeb67c52a3b27",
      "ccca6577676b462885b25ecae08759fe",
      "1c636fc52da541178487c67e01e4c4d3",
      "c3f51d4fafc5444cac0838db41441f00",
      "4fa3c23dac184df78771d653e6e9b385",
      "ccd2e418c85841c7b7cf9656c6cb05c7",
      "07997f2192534b7c94f2987fdc37475d",
      "daa7173d34324885b5aa6947e80c072a",
      "e0c2055abcfe423186c8a5f7ae94b4d4",
      "6a533f2207df4b088b068c14649e457a",
      "041f91356c2c41248db71051bfa65956",
      "9add90b83b084635a587bb714ac57849",
      "864e1de2672343b287e39f80c052671c",
      "a9e44407d639462fa91ba5b636508426",
      "d3a1513a4473435ca1296f58f1557db3",
      "c9573f3d73784e16bdee3a8d9586abc1",
      "8c6286fe92014244b1f4765a67d6f9fe",
      "9b5a4cb599cc4ac5acc366e73d664fee",
      "08ccdcb32b9d4563b4037d423c4d83e5"
     ]
    },
    "id": "exk5-04OFGj6",
    "outputId": "1cb464e8-93bc-4996-95b4-926139389581"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a18c172b2c24287831febee093165c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c2055abcfe423186c8a5f7ae94b4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1 = AutoModel.from_pretrained(model_name_1, use_auth_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "f6bf8d6df1c440309d2e288a9cea8fd6",
      "55a20c56c56244f28b435ebb29986b47",
      "e228121fad1f47d088c7f64f664cb5d2",
      "78cf72a8a5c242c0b568732c6ebe9003",
      "036cecb5a8ae44fa9de080b83f9b46ee",
      "ca781f2efa2a4547a350c7ff013e98ea",
      "78467b85b43c43368a764f20fb5a679b",
      "51ebee83117b4bcba206770e724e3d37",
      "481e5168ee4a408b9e5b6135743214f6",
      "04f498d800de47a49c94d496190a43a1",
      "a96540ff242a49cbabcc5a24abc4052f",
      "8c0def4d05fb40eaa3a8b968197df858",
      "2a0eb14cbb75471a89f52535364d7d8d",
      "4ed955c6dcb84d14aa03ce31b64f4169",
      "735cd3516d6a40f19bab6949670f4ece",
      "e49d6ff1eae7411790ee21870cc69b65",
      "ea87ea710372465c826bc9bfc0716733",
      "199aaa932f3f424eb0e35e4f7e8d4ad4",
      "a547c296cca2498dac3b19607b07f5c5",
      "6e6bfe8ce12d44309322e69ed9b68358",
      "d81260db2c2b4dbba26611f93bcdef8b",
      "c286f376e5884d76856b5132e1f65749",
      "5a12f1024c5042f8b0aa79519be952c7",
      "97f929ca075f4abcb9a2014e4d99279f",
      "9753e65db414450ab99d7338f5e8106f",
      "4529340eb03d48a482b55fb87b167f84",
      "c5d69f67f2674c12ad746ce77e8cdc9c",
      "8fb7b116d70b4cde8d8793d075934427",
      "54f1bc01725249aeb6e794a42915a9d3",
      "ffa4f47dc59448f29e83c0dc8742011f",
      "867908e49e144668b86332353412ffcc",
      "93dfdcac779446c1aaa90c66c1b4bf1d",
      "177deb0471c545daa0d6d5314b2ec3ba"
     ]
    },
    "id": "8eH8ySRkFOBw",
    "outputId": "a367584b-8ccd-484b-f9b6-d7b444f8ffe7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bf8d6df1c440309d2e288a9cea8fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0def4d05fb40eaa3a8b968197df858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a12f1024c5042f8b0aa79519be952c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1oQ25MDGOcT",
    "outputId": "e0c85a25-9e10-4893-8415-3bc033cef0db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='bert-base-multilingual-uncased', vocab_size=105879, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faAw4TOaFSyE",
    "outputId": "eb7783fb-d230-400f-e416-9bc550d1c359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRpbVZmFUVNC",
    "outputId": "707c60ea-1e37-48ab-81c6-4a22b5b59c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"The sun rises in the east.\"\n",
    "text_2 = \"Elephants are intelligent creatures.\"\n",
    "\n",
    "encoded_input_1 = tokenizer_1(text_1, return_tensors='pt',padding=True, truncation=True)\n",
    "encoded_input_2 = tokenizer_1(text_2, return_tensors='pt',padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "  embeddings1 = model_1(**encoded_input_1).last_hidden_state.mean(dim=1)  # Taking the mean of token embeddings\n",
    "  embeddings2 = model_1(**encoded_input_2).last_hidden_state.mean(dim=1)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(embeddings1,embeddings2)\n",
    "print(f\"Cosine Similarity between {[text_1,text_2]}:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij4se1SNwkhB"
   },
   "source": [
    "## making it generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mQ3P7RbQVEmJ"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model, tokenizer, examples:dict):\n",
    "  embeddings = {}\n",
    "  for key in examples:\n",
    "    encoded_input_1 = tokenizer(examples[key][0], return_tensors='pt',padding=True, truncation=True)\n",
    "    encoded_input_2 = tokenizer(examples[key][1], return_tensors='pt',padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "      embeddings1 = model(**encoded_input_1).last_hidden_state.mean(dim=1)  # Taking the mean of token embeddings\n",
    "      embeddings2 = model(**encoded_input_2).last_hidden_state.mean(dim=1)\n",
    "    embeddings[key] = [embeddings1,embeddings2]\n",
    "  print(\"embedding size : \",embeddings[0][0].shape)\n",
    "  return embeddings\n",
    "\n",
    "def get_cosine_simmilarity(examples,embeddings):\n",
    "  from sklearn.metrics.pairwise import cosine_similarity\n",
    "  # cosine simmilarity\n",
    "  results = []\n",
    "  for key in embeddings:\n",
    "    similarity = cosine_similarity(embeddings[key][0], embeddings[key][1])\n",
    "    results.append(similarity)\n",
    "    print(f\"Cosine Similarity between {examples[key]}:\", similarity)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5EGvUKBVHZI",
    "outputId": "c5fddbdd-39d2-4818-de5c-53f52f614059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n"
     ]
    }
   ],
   "source": [
    "examples = {\n",
    "    0:[\"The sun rises in the east.\",\"Elephants are intelligent creatures.\"]\n",
    "}\n",
    "embeddings = get_embeddings(model_1, tokenizer_1, examples)\n",
    "result = get_cosine_simmilarity(examples,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIMofPRcVvGJ"
   },
   "source": [
    "## few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hpFyWW6RVglx"
   },
   "outputs": [],
   "source": [
    "examples = {\n",
    "    0: [\"The sun rises in the east.\",\"Elephants are intelligent creatures.\"],   # it is to check model's accuracy - 2 very dissimilar text\n",
    "    1: [\"i love cats\",\"i love dogs\"],                                           # it is to check model's accuracy - 2 very similar text\n",
    "\n",
    "    2:[\"में आज पेमेंट कर दूंगा\",\"I'll make payment today\"],                            # one hindi one english text\n",
    "    3:[\"में आज पेमेंट कर दूंगा\",\"आज साम को ही कर दूंगा पेमेंट\"],                              # both hindi text\n",
    "    4:[\"i'll complete transaction by end of the day\",\"i will make payment today\"], # both english text\n",
    "\n",
    "    5:[\"me aaj payment kar dunga\", \"aaj saam se pehle payment ho jaye ga\"],     # both hinglish text\n",
    "    6:[\"do din pehle hi payment ho gaya \",\"payment is already completed 2 days back\"],  # hinglish and english text\n",
    "    7:[\"do din pehle hi payment ho gaya \", \"दो दिन पहले ही पेमेंट हो गया है\"]  ,          # hinglish and hindi\n",
    "\n",
    "    8:[\"आज नहीं कर पाउगा पेमेंट will do it tomorrow morning\",\"aaj nahi kar payga payment will do it tomorrow morning\"],\n",
    "    9:[\"आज नहीं कर पाउगा पेमेंट will do it tomorrow morning\",\"i'll not be able to do payment today will do it tomorrow morning\"],\n",
    "\n",
    "    # examples with entity\n",
    "    10:[\"में गूगलपे से कर दूंगा\",\"I will pay via googlepay\"],\n",
    "    11:[\"में गूगलपे से कर दूंगा\",\"me googlepay se kar dunga\"],\n",
    "    12:[\"me googlepay kar denga\", \"i will pay using googlepay\"],\n",
    "\n",
    "    13:[\"में googlepay से कर दूंगा\",\"I will pay via googlepay\"],\n",
    "    14:[\"में googlepay से कर दूंगा\",\"me googlepay se kar dunga\"],\n",
    "\n",
    "    15:[\"mera name ganesh he\",\"My name is ganesh\"],\n",
    "    16:[\"में 31st august को कर दूंगा\",\"me 31st august ko kar dunga\"],\n",
    "    17:[\"में 31st august को कर दूंगा\",\"i'll do it by 31st august\"],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb-u3Q1dVmaP"
   },
   "source": [
    "## check for bert-base-multilingual-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfgHelrHMBtK",
    "outputId": "588502c1-7020-427b-ec32-263e1d9c3cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.966812]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.5628961]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.88884926]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.70899254]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.7154846]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[0.41329274]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[0.4324294]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[0.7251013]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.6734522]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.51611906]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[0.4522512]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.65438783]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.65804225]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.5695174]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[0.8628424]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.62380624]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.66751325]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_1 = get_embeddings(model_1, tokenizer_1, examples)\n",
    "results_1 = get_cosine_simmilarity(examples,embeddings_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxI6Vsnh1X1P",
    "outputId": "d83e6f2b-1086-4bc3-c74c-f774a307aceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['में आज पेमेंट कर दूंगा', \"I'll make payment today\"] [[0.5628961]]\n"
     ]
    }
   ],
   "source": [
    "print(examples[2],results_1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D92YXr_S6-h"
   },
   "source": [
    "# check for xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200,
     "referenced_widgets": [
      "5a575b81752c4abb89f3f770a1f505c5",
      "ad3be8d532fe47e8857f72f18afbd37a",
      "0dd2625c38364e0c9d69ef27ee3a49e1",
      "5754174e5b544b948b3ccc920a286a87",
      "f74733ec782648c780dc4ad979f22634",
      "9006e241d4d64ef38875045f2f8e6968",
      "5a9591516b974490af8bb76639a8e54d",
      "2324eba808124232b3207d726a969331",
      "0c2c4b8531b5493b8c92e28bf95d582e",
      "15da458bb29944529219ad9bb5c92db8",
      "be2ed84095ae4198b07e46b34f2a5df4",
      "0eb94d43b8f34062b1b8c03c2ee82575",
      "161a97492582498a8e905852b975422e",
      "448d91444ea74c519f01ffe6f2d0856a",
      "5cba3d30221f4612bdb9563c2a1aead6",
      "072024f1f28843119ed87f8a344683d6",
      "ef08d78ff4e748d6b1bc0ecc44ca2648",
      "740eb90f801141159e4bf71026ac5694",
      "a601ee1851204d5eb2007c897f49fb29",
      "abe1d91bd31944979848b56e26fdd1de",
      "e1bb44615ede409d8b8e643fcce96cf3",
      "1a4b4e759a404d259be422880315fd73",
      "200b44f734b54a4da96af1480caf7aa6",
      "2364bb9b1cc84401b01047243c0d8b9d",
      "d45cf512407249b789ff94233f16ca85",
      "d42d9f20449549cebec57223f9897e98",
      "163def374c29454fa18474072be768e6",
      "0a31185c46a345fa83adcf85aa0f3295",
      "e3bd262dfc184846a44edf357402701d",
      "cb3d2dff2ed14506a2a7410d3f8dac17",
      "3bf24649fa604b21bc60e920c103f90a",
      "8d9354056a23403092709bf5d0fe79b1",
      "cee240d3984d4069837762e216d2a9de",
      "82e10d29a27145d3ae079b29c15d0abe",
      "2c5cb21149d444b786fb09c7302e6bef",
      "ec660036f3524f73a6b1b16800937ce8",
      "4b819a16210b47f883aaf25a02d6f1b5",
      "56ce1f665ef340b98f3d34902abb1ce8",
      "5d167b4461ee467d8b75ffc7e798bb7c",
      "6243a20c5d254ef7933fa237707d2888",
      "ec3e5e2dd16b469383d1873bbe329085",
      "50175833f56c433d8dc77e42cf6c8b97",
      "07d05de9a6674728a2b8af67b25484d0",
      "d458b34c46ef427db492bf285a2bbc54"
     ]
    },
    "id": "S3cNk4drS5u2",
    "outputId": "98567a4c-c77b-40ac-a734-d5c2a3a60ae9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a575b81752c4abb89f3f770a1f505c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb94d43b8f34062b1b8c03c2ee82575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200b44f734b54a4da96af1480caf7aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e10d29a27145d3ae079b29c15d0abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2 = model = AutoModel.from_pretrained(model_name_2, use_auth_token=access_token)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOQWvzJ-TTKC",
    "outputId": "9b01c757-9c21-4481-c040-2eef5a887f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.99575526]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.9995593]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.99506414]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.99903774]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.997167]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.99608314]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[0.99220085]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[0.99329627]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[0.9950456]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.99542135]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.99637043]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[0.99478865]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.99520475]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.99677545]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.9952321]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[0.9978698]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.99615437]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.9968206]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_2 = get_embeddings(model_2, tokenizer_2, examples)\n",
    "results_2 = get_cosine_simmilarity(examples,embeddings_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqtOg4xJWOTN"
   },
   "source": [
    "## check with google/muril-large-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "42c2a7f1ccef45699bae2e009b769ec9",
      "386b6969821b4107acfb3944a80f3966",
      "f4bebcc41715476ba62a93a6189ef593",
      "2e4262593ef54034977cfef068a0f186",
      "8fc84076dc0248b4affb697a3f8a4b6d",
      "c70120fb3f524f79872c9f36b228b08d",
      "a263cd5ee5634ee0a7d3810cc718c440",
      "2a1d82c0618d44acb72113ae2c2e7258",
      "63f6ef41bf18465ca07b9f1443692971",
      "26200aeee3fc49adb54f01737d43aa5b",
      "d9dd5e527979482188d0c37925bf3091",
      "c97b872466774494a750ff820a4e4a54",
      "60b437c352c541aa8ffc07213bc2ee98",
      "a91a859ffc4041a38622bf5a242f4214",
      "9d55e8be796c4866a0b91be8db03fb52",
      "593801dd3bb14c87b7b9b7ab14fe75ab",
      "9bf6d49572144e399c79e5564eae4111",
      "ef145e4efc07455599fefed9e278a0c7",
      "3cbc9d29e0df43d28b0f062963456743",
      "7b5675f2d7c6454dadb5fd85d74c5398",
      "a79dc015197443f89861926551e055c9",
      "ee99d467aad94a8b8bd62ff9e2a4aabd",
      "0750ce2b3c884541b5d52c336fb0648b",
      "3e18c89c1fc14d9e9b85d208d245c3d0",
      "a9acaa3b5e9e48b2872ba315b583a082",
      "70c11bc43d5e436f93dc9e7cb9400a7b",
      "08a6b887cd644f9994ebb3898ca936c6",
      "5fd4ea6a1d2f4431ab22411a5ead28f4",
      "296acb0f82b44cd2bc4a566add90d026",
      "b35535cd8ee74de6a0631832880dc43c",
      "084ea15c7c684ee09faf31fd2a4ee1bd",
      "e08b887fbabd4416ba0f70c4cca84296",
      "a7b75f20f9d9408a8706b99dfae1f954",
      "b76824ac69db4abf86203d07f2f6d852",
      "41d11e734fb5438fa5ceb91e5841e863",
      "77048ba45c904f8ca0ee408b6fe07179",
      "0a002b721b4140bbbba502dda559314a",
      "375bad7e0fb3492db6279a1afb5a9e1f",
      "4ae62891444f4610a350173f26336b0d",
      "04a411d068e64442ada7d49c4c3014ec",
      "0fb83ca8e93b462c83124e7f667055cf",
      "27886d8249a246e08a77d3be55a8ba29",
      "c4905ed760984c7faa4604ef8957dd20",
      "5b29e0a227da481d9dec2f66e06fcbf9",
      "759dc7733be841579c4d2b1dbcc3d5bc",
      "928e82d65cf54ff9ae5995135fd95ef2",
      "487ed36e74754165bae207d9850202bd",
      "92533bc3c9bd439aa7bff55ed55751a8",
      "bc16d14f8f00414a95db31738bdb52b5",
      "9d7167333264468ead15bf6fdb8801fe",
      "37c247861fba4e5b8993ad314ee2085c",
      "49aa3c30d58d46d2825255c7fafe38ab",
      "3c67408f7aaf42d5ab90e6615de1622e",
      "6560c73bc90e497e97d888c3c8941fc7",
      "38351f28d8264f608e7874431ef3e881"
     ]
    },
    "id": "gK7ohmw6TgUg",
    "outputId": "fd9e85b8-de32-46d9-bb1a-777b2c78c187"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c2a7f1ccef45699bae2e009b769ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/406 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97b872466774494a750ff820a4e4a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0750ce2b3c884541b5d52c336fb0648b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76824ac69db4abf86203d07f2f6d852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759dc7733be841579c4d2b1dbcc3d5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_3 = model = AutoModel.from_pretrained(model_name_3, use_auth_token=access_token)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model_name_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0ruOTgnWcFQ",
    "outputId": "8a4b92d6-def0-4ba1-cb36-7ab3241a17cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 1024])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.9125152]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.9658783]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.86679196]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.952119]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.90588737]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.60462487]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[-0.67666674]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[-0.51547605]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[-0.3034185]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.567041]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.88340235]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[-0.17708397]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.69350076]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.886293]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.04100528]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[-0.37116796]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.06417519]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.7315647]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_3 = get_embeddings(model_3, tokenizer_3, examples)\n",
    "results_3 = get_cosine_simmilarity(examples,embeddings_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGoVZr8I46aR"
   },
   "source": [
    "## export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TAxjQoBie9N8"
   },
   "outputs": [],
   "source": [
    "j = {}\n",
    "j[\"examples\"] = examples.values()\n",
    "j[\"bert-base-multilingual-uncased\"] = results_1\n",
    "j[\"xlm-roberta-base\"] = results_2\n",
    "j[\"google/muril-large-cased\"] = results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8G98i3qDvOqx",
    "outputId": "13b6d4b9-b749-4b5b-bf82-a28735f45ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            examples  \\\n",
      "0  [The sun rises in the east., Elephants are int...   \n",
      "1                         [i love cats, i love dogs]   \n",
      "2  [में आज पेमेंट कर दूंगा, I'll make payment today]   \n",
      "3  [में आज पेमेंट कर दूंगा, आज साम को ही कर दूंगा...   \n",
      "4  [i'll complete transaction by end of the day, ...   \n",
      "\n",
      "  bert-base-multilingual-uncased xlm-roberta-base google/muril-large-cased  \n",
      "0                 [[0.51830876]]   [[0.99575526]]            [[0.9125152]]  \n",
      "1                   [[0.966812]]    [[0.9995593]]            [[0.9658783]]  \n",
      "2                  [[0.5628961]]   [[0.99506414]]           [[0.86679196]]  \n",
      "3                 [[0.88884926]]   [[0.99903774]]             [[0.952119]]  \n",
      "4                 [[0.70899254]]     [[0.997167]]           [[0.90588737]]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(j)\n",
    "print(data.head())\n",
    "data.to_csv(\"results.csv\")\n",
    "# data.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "X25itqpkvOno"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "up-ep1d9vOcW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVHZYlEA5b84"
   },
   "source": [
    "## Embedding dimension\n",
    "- bert-base-multilingual-uncased : 768\n",
    "- xlm-roberta-base : 768\n",
    "- google/muril-large-cased : 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sWVBonLYCyb"
   },
   "source": [
    "## The model architecture is one of the supported language models (check that the model_type in config.json is listed in the table's column model_name)\n",
    "  - bert-base-multilingual-uncased (BERT is supported)\n",
    "  - xlm-roberta-base (RoBERTa is supported)\n",
    "  - google/muril-large-cased (it is BERT model trained on 17 indian language so it is also supported)\n",
    "\n",
    "\n",
    "## The model has pretrained Tensorflow weights (check that the file tf_model.h5 exists)\n",
    "  - bert-base-multilingual-uncased (.h5 file exists)\n",
    "  - xlm-roberta-base (.h5 file exists)\n",
    "  - google/muril-large-cased (.h5 is not exsist but we can get it from pytorch_model.bin)\n",
    "\n",
    "## The model uses the default tokenizer (config.json should not contain a custom tokenizer_class setting)\n",
    "  - bert-base-multilingual-uncased (does not have any custom tokenizer)\n",
    "  - xlm-roberta-base (does not have any custom tokenizer)\n",
    "  - google/muril-large-cased (does not have any custom tokenizer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
