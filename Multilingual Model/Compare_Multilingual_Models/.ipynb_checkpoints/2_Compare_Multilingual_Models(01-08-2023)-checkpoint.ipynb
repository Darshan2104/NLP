{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnn1_DUtClRX"
   },
   "source": [
    "## Load these models and check embedding simmilarity for normal hindi, english and hinglish\n",
    "  - bert-base-multilingual-uncased\n",
    "  - xlm-roberta-base\n",
    "  - MuRil (for embedding simmilarity)\n",
    "\n",
    "##  Check if bert-base-multilingual-uncased can handle multilingual two languages in the same bot\n",
    "##  Check if xlm-roberta-base satisfies following conditions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKOBnEflCe42",
    "outputId": "2e5b1d1b-fda4-430a-b0c9-7a31881bcf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=75b4ff9e36b74c6c641cafd0d980c60d9da2d31bb2a366295a75770c70adf7dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install tokenizers\n",
    "!pip install sentencepiece\n",
    "!pip install scipy\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qlmMBXpQKblj"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VWpOaTxoEizX"
   },
   "outputs": [],
   "source": [
    "access_token = \"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\"\n",
    "model_name_1 = \"bert-base-multilingual-uncased\"\n",
    "model_name_2 = \"xlm-roberta-base\"\n",
    "model_name_3 = \"google/muril-large-cased\"\n",
    "model_name_4 = \"sentence-transformers/LaBSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0Zb2SHHCEYF3"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "efb45fb3a55e4d6e883396e75a236f98",
      "8b22f1c93bff4d6896aefd2f205fb29c",
      "cb547923d4c94569a91e588ff359518a",
      "7f2967d233b247b2bf0d300fbccf65ed",
      "636641891b4a4e3c826d3e2ceb73a6e3",
      "ba491eaaefd04653881f8d0bcda19616",
      "311f5941a8f943339cb801f0a9afee72",
      "7c486791957241d6b631b5f1037e7d96",
      "fcdc12006adf45c3893dbc237507b93e",
      "0f651fd194854a10a836047e215b4ef1",
      "048b3dc730144f95af660c2ad9d70530",
      "b5c883283e314c8db82f8431f3d7f9b7",
      "b71b02e51a7d426abfbacea169392285",
      "9e39abbac6264b209e95aca178d7c169",
      "6f3422ce373449cda52c6973deda5b02",
      "c1e96f3df8164c49969e80067591abd9",
      "e40444451723437085d346c4ee87809e",
      "1a7e322e6c774b04b747d947eac4804b",
      "a07853536ced4ad1b71a96c45ac09639",
      "effad279853e40f58b6f5436c735a5a0",
      "efa318b5cb324ae3bcbd3e1617f5da9a",
      "771fb117b1fa4e0e9647c24c8569aebd"
     ]
    },
    "id": "exk5-04OFGj6",
    "outputId": "f1b44edf-3ab1-48aa-da5c-d64d7ea32383"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb45fb3a55e4d6e883396e75a236f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c883283e314c8db82f8431f3d7f9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1 = AutoModel.from_pretrained(model_name_1, use_auth_token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "8bc78fad42ab48eeb87f51b0c880d641",
      "9a9ff31576bc499cb66b9bf9f823b666",
      "59aba3b6ba9a4eb69da43bf088b363d2",
      "e41f95cbf6424ca2a0dbed01213ccd4d",
      "b719253f515043458e0f88fc17bc9a4b",
      "f26b7c1c7b594ec4b77b36aaccdaf642",
      "d2f1cb9eb8ab4019b5d6b6b03ea1025a",
      "d2ed2c2310164097927c0294fc6ad342",
      "8d4dc054520840d4b4eebb83bc12d786",
      "08e259469852400e92d4b035ef4981af",
      "aca7748c25564f9aaf9888cff03b4ec1",
      "74a1f418af5a42efbaa379e87105de52",
      "9bf6a52a80d94405af624bd901ba8aa7",
      "994f035deb5a485ebd0f04b08a0de140",
      "1d232312556f43939db1c8db4c1eb65e",
      "ff962882c53e4ea38c896732309c404a",
      "fe9ef9ad351d4e9c86ed8e085dbe00ef",
      "ffa186b01b5344b3b9e20a8f90984883",
      "519bccbd29d24e1b8803abc3425fd8f7",
      "79230b43b5414a1990971419547f9a4d",
      "86628ce4efef43fb84a92fa58a37b3af",
      "30b16077e67e491788b51078cb808fbd",
      "aac46bfa3e274a4bae59886608423375",
      "8e6c7c1064aa43d390104d8e9a55b76f",
      "2ddedfa6a9da44a08206d0d9c13c3423",
      "740c9b6908614921977643819d6cd737",
      "da595d3fe0fc454f9740e59acc209e20",
      "8cdf274964c94ec0a9efd3c51d7d4281",
      "ebb8bc8161664464bbac7a2e299a6f07",
      "eef001d47e14443285e8185565d0eca7",
      "75cd1363a9a54f669144e6412e924bbd",
      "c22f76f43fe943d4a54e945ef3535e39",
      "477c56b597ae4307bfbfb1de49f972c9"
     ]
    },
    "id": "8eH8ySRkFOBw",
    "outputId": "967ad9c4-88dc-4c3e-96bf-54435cb82a59"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc78fad42ab48eeb87f51b0c880d641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a1f418af5a42efbaa379e87105de52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac46bfa3e274a4bae59886608423375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_name_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1oQ25MDGOcT",
    "outputId": "943f643a-83d1-4e8c-9672-43b859fd92bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='bert-base-multilingual-uncased', vocab_size=105879, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faAw4TOaFSyE",
    "outputId": "1524d0ce-e7df-4ed6-e455-0edd7a16aa13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRpbVZmFUVNC",
    "outputId": "5c52df8d-2659-4343-ced8-099386dee54b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"The sun rises in the east.\"\n",
    "text_2 = \"Elephants are intelligent creatures.\"\n",
    "\n",
    "encoded_input_1 = tokenizer_1(text_1, return_tensors='pt',padding=True, truncation=True)\n",
    "encoded_input_2 = tokenizer_1(text_2, return_tensors='pt',padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "  embeddings1 = model_1(**encoded_input_1).last_hidden_state.mean(dim=1)  # Taking the mean of token embeddings\n",
    "  embeddings2 = model_1(**encoded_input_2).last_hidden_state.mean(dim=1)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(embeddings1,embeddings2)\n",
    "print(f\"Cosine Similarity between {[text_1,text_2]}:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij4se1SNwkhB"
   },
   "source": [
    "## making it generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mQ3P7RbQVEmJ"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model, tokenizer, examples:dict):\n",
    "  embeddings = {}\n",
    "  for key in examples:\n",
    "    encoded_input_1 = tokenizer(examples[key][0], return_tensors='pt',padding=True, truncation=True)\n",
    "    encoded_input_2 = tokenizer(examples[key][1], return_tensors='pt',padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "      embeddings1 = model(**encoded_input_1).last_hidden_state.mean(dim=1)  # Taking the mean of token embeddings\n",
    "      embeddings2 = model(**encoded_input_2).last_hidden_state.mean(dim=1)\n",
    "    embeddings[key] = [embeddings1,embeddings2]\n",
    "  print(\"embedding size : \",embeddings[0][0].shape)\n",
    "  return embeddings\n",
    "\n",
    "def get_cosine_simmilarity(examples,embeddings):\n",
    "  from sklearn.metrics.pairwise import cosine_similarity\n",
    "  # cosine simmilarity\n",
    "  results = []\n",
    "  for key in embeddings:\n",
    "    similarity = cosine_similarity(embeddings[key][0], embeddings[key][1])\n",
    "    results.append(similarity)\n",
    "    print(f\"Cosine Similarity between {examples[key]}:\", similarity)\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5EGvUKBVHZI",
    "outputId": "ec4a05d1-58d0-4f52-8494-40d9576833e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n"
     ]
    }
   ],
   "source": [
    "examples = {\n",
    "    0:[\"The sun rises in the east.\",\"Elephants are intelligent creatures.\"]\n",
    "}\n",
    "embeddings = get_embeddings(model_1, tokenizer_1, examples)\n",
    "result = get_cosine_simmilarity(examples,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIMofPRcVvGJ"
   },
   "source": [
    "## few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "hpFyWW6RVglx"
   },
   "outputs": [],
   "source": [
    "examples = {\n",
    "    0: [\"The sun rises in the east.\",\"Elephants are intelligent creatures.\"],   # it is to check model's accuracy - 2 very dissimilar text\n",
    "    1: [\"i love cats\",\"i love dogs\"],                                           # it is to check model's accuracy - 2 very similar text\n",
    "\n",
    "    2:[\"में आज पेमेंट कर दूंगा\",\"I'll make payment today\"],                            # one hindi one english text\n",
    "    3:[\"में आज पेमेंट कर दूंगा\",\"आज साम को ही कर दूंगा पेमेंट\"],                              # both hindi text\n",
    "    4:[\"i'll complete transaction by end of the day\",\"i will make payment today\"], # both english text\n",
    "\n",
    "    5:[\"me aaj payment kar dunga\", \"aaj saam se pehle payment ho jaye ga\"],     # both hinglish text\n",
    "    6:[\"do din pehle hi payment ho gaya \",\"payment is already completed 2 days back\"],  # hinglish and english text\n",
    "    7:[\"do din pehle hi payment ho gaya \", \"दो दिन पहले ही पेमेंट हो गया है\"]  ,          # hinglish and hindi\n",
    "\n",
    "    8:[\"आज नहीं कर पाउगा पेमेंट will do it tomorrow morning\",\"aaj nahi kar payga payment will do it tomorrow morning\"],\n",
    "    9:[\"आज नहीं कर पाउगा पेमेंट will do it tomorrow morning\",\"i'll not be able to do payment today will do it tomorrow morning\"],\n",
    "\n",
    "    # examples with entity\n",
    "    10:[\"में गूगलपे से कर दूंगा\",\"I will pay via googlepay\"],\n",
    "    11:[\"में गूगलपे से कर दूंगा\",\"me googlepay se kar dunga\"],\n",
    "    12:[\"me googlepay kar denga\", \"i will pay using googlepay\"],\n",
    "\n",
    "    13:[\"में googlepay से कर दूंगा\",\"I will pay via googlepay\"],\n",
    "    14:[\"में googlepay से कर दूंगा\",\"me googlepay se kar dunga\"],\n",
    "\n",
    "    15:[\"mera name ganesh he\",\"My name is ganesh\"],\n",
    "    16:[\"में 31st august को कर दूंगा\",\"me 31st august ko kar dunga\"],\n",
    "    17:[\"में 31st august को कर दूंगा\",\"i'll do it by 31st august\"],\n",
    "\n",
    "    # some examples where examples are not simmiler\n",
    "\n",
    "    18:[\"में पेमेंट नहीं करूँगा\",\"i'll not do payment\"],\n",
    "    19:[\"में पेमेंट नहीं करूँगा\",\"i'll do payment later\"],\n",
    "    20:[\"पेमेंट बाद में करूँगा\",\"i'll not do payment\"],\n",
    "    21:[\"पेमेंट बाद में करूँगा\",\"i'll do payment later\"]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb-u3Q1dVmaP"
   },
   "source": [
    "## check for bert-base-multilingual-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfgHelrHMBtK",
    "outputId": "01213e11-5b70-44f2-e902-cd88498257d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.51830876]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.966812]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.5628961]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.88884926]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.70899254]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.7154846]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[0.41329274]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[0.4324294]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[0.7251013]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.6734522]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.51611906]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[0.4522512]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.65438783]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.65804225]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.5695174]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[0.8628424]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.62380624]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.66751325]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll not do payment\"]: [[0.6542227]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll do payment later\"]: [[0.5818778]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll not do payment\"]: [[0.5954785]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll do payment later\"]: [[0.58610404]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_1 = get_embeddings(model_1, tokenizer_1, examples)\n",
    "results_1 = get_cosine_simmilarity(examples,embeddings_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxI6Vsnh1X1P",
    "outputId": "ed7c117b-8ea3-4abf-ac26-b0a4452a4160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['में आज पेमेंट कर दूंगा', \"I'll make payment today\"] [[0.5628961]]\n"
     ]
    }
   ],
   "source": [
    "print(examples[2],results_1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D92YXr_S6-h"
   },
   "source": [
    "# check for xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3cNk4drS5u2",
    "outputId": "49193ac8-fe9a-4f66-ba63-1127eb2ea9f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_2 = model = AutoModel.from_pretrained(model_name_2, use_auth_token=access_token)\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOQWvzJ-TTKC",
    "outputId": "2c8f71d6-41fd-4b38-898b-285a56656af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 768])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.99575526]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.9995593]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.99506414]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.99903774]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.997167]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.99608314]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[0.99220085]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[0.99329627]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[0.9950456]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.99542135]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.99637043]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[0.99478865]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.99520475]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.99677545]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.9952321]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[0.9978698]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.99615437]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.9968206]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll not do payment\"]: [[0.99630284]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll do payment later\"]: [[0.9965709]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll not do payment\"]: [[0.9959558]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll do payment later\"]: [[0.9968151]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_2 = get_embeddings(model_2, tokenizer_2, examples)\n",
    "results_2 = get_cosine_simmilarity(examples,embeddings_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqtOg4xJWOTN"
   },
   "source": [
    "## check with google/muril-large-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gK7ohmw6TgUg",
    "outputId": "a5b436d1-5e17-452d-9149-851c843f23f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:460: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google/muril-large-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_3 = model = AutoModel.from_pretrained(model_name_3, use_auth_token=access_token)\n",
    "tokenizer_3 = AutoTokenizer.from_pretrained(model_name_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0ruOTgnWcFQ",
    "outputId": "8b055765-864b-494f-e513-77956cb89ab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size :  torch.Size([1, 1024])\n",
      "Cosine Similarity between ['The sun rises in the east.', 'Elephants are intelligent creatures.']: [[0.9125152]]\n",
      "Cosine Similarity between ['i love cats', 'i love dogs']: [[0.9658783]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', \"I'll make payment today\"]: [[0.86679196]]\n",
      "Cosine Similarity between ['में आज पेमेंट कर दूंगा', 'आज साम को ही कर दूंगा पेमेंट']: [[0.952119]]\n",
      "Cosine Similarity between [\"i'll complete transaction by end of the day\", 'i will make payment today']: [[0.90588737]]\n",
      "Cosine Similarity between ['me aaj payment kar dunga', 'aaj saam se pehle payment ho jaye ga']: [[0.60462487]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'payment is already completed 2 days back']: [[-0.67666674]]\n",
      "Cosine Similarity between ['do din pehle hi payment ho gaya ', 'दो दिन पहले ही पेमेंट हो गया है']: [[-0.51547605]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', 'aaj nahi kar payga payment will do it tomorrow morning']: [[-0.3034185]]\n",
      "Cosine Similarity between ['आज नहीं कर पाउगा पेमेंट will do it tomorrow morning', \"i'll not be able to do payment today will do it tomorrow morning\"]: [[0.567041]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'I will pay via googlepay']: [[0.88340235]]\n",
      "Cosine Similarity between ['में गूगलपे से कर दूंगा', 'me googlepay se kar dunga']: [[-0.17708397]]\n",
      "Cosine Similarity between ['me googlepay kar denga', 'i will pay using googlepay']: [[0.69350076]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'I will pay via googlepay']: [[0.886293]]\n",
      "Cosine Similarity between ['में googlepay से कर दूंगा', 'me googlepay se kar dunga']: [[0.04100528]]\n",
      "Cosine Similarity between ['mera name ganesh he', 'My name is ganesh']: [[-0.37116796]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', 'me 31st august ko kar dunga']: [[0.06417519]]\n",
      "Cosine Similarity between ['में 31st august को कर दूंगा', \"i'll do it by 31st august\"]: [[0.7315647]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll not do payment\"]: [[0.790928]]\n",
      "Cosine Similarity between ['में पेमेंट नहीं करूँगा', \"i'll do payment later\"]: [[0.7940219]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll not do payment\"]: [[0.9137787]]\n",
      "Cosine Similarity between ['पेमेंट बाद में करूँगा', \"i'll do payment later\"]: [[0.91630363]]\n"
     ]
    }
   ],
   "source": [
    "embeddings_3 = get_embeddings(model_3, tokenizer_3, examples)\n",
    "results_3 = get_cosine_simmilarity(examples,embeddings_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNdiq0Ot1yWP"
   },
   "source": [
    "## check with sentence-trasnformer (LaBSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PT9XSaSg1xhl"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "def get_cosine_simmilarity_for_labse(input_text_pair_list):\n",
    "  from sklearn.metrics.pairwise import cosine_similarity\n",
    "  import torch\n",
    "  # cosine simmilarity\n",
    "  result = []\n",
    "  for key, value in input_text_pair_list.items():\n",
    "    embeddings = model.encode(value)\n",
    "    results = []\n",
    "    similarity = cosine_similarity(torch.tensor(embeddings[0].reshape(1, -1)), torch.tensor(embeddings[1].reshape(1, -1)))\n",
    "    result.append(similarity)\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mDv59vcC22SA"
   },
   "outputs": [],
   "source": [
    "result_4 = get_cosine_simmilarity_for_labse(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "spFM6WmAK8wi"
   },
   "source": [
    "## combine LaBSE + XLM-Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "tl2qj37wLAYn"
   },
   "outputs": [],
   "source": [
    "# XLM-Roberta embeddings\n",
    "\n",
    "# embeddings_2[17][0].shape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "result_combind = []\n",
    "result_combind_mul = []\n",
    "ans={}\n",
    "for key, value in examples.items():\n",
    "  ans[key] = model.encode(value)\n",
    "  example_1_1 = embeddings_2[0][0]\n",
    "  example_1_2 = embeddings_2[0][1]\n",
    "\n",
    "  example_2_1 = torch.tensor(ans[0][0].reshape(1, -1))\n",
    "  example_2_2 = torch.tensor(ans[0][1].reshape(1, -1))\n",
    "\n",
    "# apply operation here...........\n",
    "  combined_embeddings_1 = torch.cat((example_1_1, example_2_1), dim=1)\n",
    "  combined_embeddings_2 = torch.cat((example_1_2, example_2_2), dim=1)\n",
    "\n",
    "  # vector multiplication is good for machine translation task\n",
    "  combined_embeddings_1_1 = example_1_1 * example_2_1\n",
    "  combined_embeddings_2_1 = example_1_2 * example_2_2\n",
    "# apply operation here...........\n",
    "\n",
    "\n",
    "  result = cosine_similarity(combined_embeddings_1,combined_embeddings_2)\n",
    "  result_combind.append(result)\n",
    "\n",
    "  result_1 = cosine_similarity(combined_embeddings_1_1,combined_embeddings_2_1)\n",
    "  result_combind_mul.append(result_1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqdGojkqMIRx",
    "outputId": "c3c32da8-a49c-4ea9-9772-a10b39d70f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32), array([[0.9932801]], dtype=float32)]\n",
      "[array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32), array([[0.60988194]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(result_combind)\n",
    "print(result_combind_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGoVZr8I46aR"
   },
   "source": [
    "## export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "TAxjQoBie9N8"
   },
   "outputs": [],
   "source": [
    "j = {}\n",
    "j[\"examples\"] = examples.values()\n",
    "j[\"bert-base-multilingual-uncased\"] = results_1\n",
    "j[\"xlm-roberta-base\"] = results_2\n",
    "j[\"google/muril-large-cased\"] = results_3\n",
    "j[\"sentence-transformers/LaBSE\"]= result_4\n",
    "j[\"concat_XLM_LaBSE\"] = result_combind\n",
    "j[\"multiply_XLM_LaBSE\"]=result_combind_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8G98i3qDvOqx",
    "outputId": "16612fcb-e141-43be-be08-b8c1e7aac64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            examples  \\\n",
      "0  [The sun rises in the east., Elephants are int...   \n",
      "1                         [i love cats, i love dogs]   \n",
      "2  [में आज पेमेंट कर दूंगा, I'll make payment today]   \n",
      "3  [में आज पेमेंट कर दूंगा, आज साम को ही कर दूंगा...   \n",
      "4  [i'll complete transaction by end of the day, ...   \n",
      "\n",
      "  bert-base-multilingual-uncased xlm-roberta-base google/muril-large-cased  \\\n",
      "0                 [[0.51830876]]   [[0.99575526]]            [[0.9125152]]   \n",
      "1                   [[0.966812]]    [[0.9995593]]            [[0.9658783]]   \n",
      "2                  [[0.5628961]]   [[0.99506414]]           [[0.86679196]]   \n",
      "3                 [[0.88884926]]   [[0.99903774]]             [[0.952119]]   \n",
      "4                 [[0.70899254]]     [[0.997167]]           [[0.90588737]]   \n",
      "\n",
      "  sentence-transformers/LaBSE concat_XLM_LaBSE multiply_XLM_LaBSE  \n",
      "0              [[0.13202727]]    [[0.9932801]]     [[0.60988194]]  \n",
      "1               [[0.9373624]]    [[0.9932801]]     [[0.60988194]]  \n",
      "2               [[0.9534264]]    [[0.9932801]]     [[0.60988194]]  \n",
      "3              [[0.86270237]]    [[0.9932801]]     [[0.60988194]]  \n",
      "4               [[0.6288543]]    [[0.9932801]]     [[0.60988194]]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(j)\n",
    "print(data.head())\n",
    "data.to_csv(\"results.csv\")\n",
    "# data.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "X25itqpkvOno",
    "outputId": "b41ad97f-fc24-45b7-c96f-d9b0c1013872"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7d5316d6-c39f-45ad-8fe1-a1f34680dfa5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>examples</th>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <th>google/muril-large-cased</th>\n",
       "      <th>sentence-transformers/LaBSE</th>\n",
       "      <th>concat_XLM_LaBSE</th>\n",
       "      <th>multiply_XLM_LaBSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[में पेमेंट नहीं करूँगा, i'll not do payment]</td>\n",
       "      <td>[[0.6542227]]</td>\n",
       "      <td>[[0.99630284]]</td>\n",
       "      <td>[[0.790928]]</td>\n",
       "      <td>[[0.97075427]]</td>\n",
       "      <td>[[0.9932801]]</td>\n",
       "      <td>[[0.60988194]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[में पेमेंट नहीं करूँगा, i'll do payment later]</td>\n",
       "      <td>[[0.5818778]]</td>\n",
       "      <td>[[0.9965709]]</td>\n",
       "      <td>[[0.7940219]]</td>\n",
       "      <td>[[0.774329]]</td>\n",
       "      <td>[[0.9932801]]</td>\n",
       "      <td>[[0.60988194]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[पेमेंट बाद में करूँगा, i'll not do payment]</td>\n",
       "      <td>[[0.5954785]]</td>\n",
       "      <td>[[0.9959558]]</td>\n",
       "      <td>[[0.9137787]]</td>\n",
       "      <td>[[0.7267952]]</td>\n",
       "      <td>[[0.9932801]]</td>\n",
       "      <td>[[0.60988194]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[पेमेंट बाद में करूँगा, i'll do payment later]</td>\n",
       "      <td>[[0.58610404]]</td>\n",
       "      <td>[[0.9968151]]</td>\n",
       "      <td>[[0.91630363]]</td>\n",
       "      <td>[[0.9339098]]</td>\n",
       "      <td>[[0.9932801]]</td>\n",
       "      <td>[[0.60988194]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d5316d6-c39f-45ad-8fe1-a1f34680dfa5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7d5316d6-c39f-45ad-8fe1-a1f34680dfa5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7d5316d6-c39f-45ad-8fe1-a1f34680dfa5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-79bf3d52-e68e-4498-908b-b5925192980d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79bf3d52-e68e-4498-908b-b5925192980d')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-79bf3d52-e68e-4498-908b-b5925192980d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                           examples  \\\n",
       "18    [में पेमेंट नहीं करूँगा, i'll not do payment]   \n",
       "19  [में पेमेंट नहीं करूँगा, i'll do payment later]   \n",
       "20     [पेमेंट बाद में करूँगा, i'll not do payment]   \n",
       "21   [पेमेंट बाद में करूँगा, i'll do payment later]   \n",
       "\n",
       "   bert-base-multilingual-uncased xlm-roberta-base google/muril-large-cased  \\\n",
       "18                  [[0.6542227]]   [[0.99630284]]             [[0.790928]]   \n",
       "19                  [[0.5818778]]    [[0.9965709]]            [[0.7940219]]   \n",
       "20                  [[0.5954785]]    [[0.9959558]]            [[0.9137787]]   \n",
       "21                 [[0.58610404]]    [[0.9968151]]           [[0.91630363]]   \n",
       "\n",
       "   sentence-transformers/LaBSE concat_XLM_LaBSE multiply_XLM_LaBSE  \n",
       "18              [[0.97075427]]    [[0.9932801]]     [[0.60988194]]  \n",
       "19                [[0.774329]]    [[0.9932801]]     [[0.60988194]]  \n",
       "20               [[0.7267952]]    [[0.9932801]]     [[0.60988194]]  \n",
       "21               [[0.9339098]]    [[0.9932801]]     [[0.60988194]]  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "up-ep1d9vOcW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVHZYlEA5b84"
   },
   "source": [
    "## Embedding dimension\n",
    "- bert-base-multilingual-uncased : 768\n",
    "- xlm-roberta-base : 768\n",
    "- google/muril-large-cased : 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sWVBonLYCyb"
   },
   "source": [
    "## The model architecture is one of the supported language models (check that the model_type in config.json is listed in the table's column model_name)\n",
    "  - bert-base-multilingual-uncased (BERT is supported)\n",
    "  - xlm-roberta-base (RoBERTa is supported)\n",
    "  - google/muril-large-cased (it is BERT model trained on 17 indian language so it is also supported)\n",
    "\n",
    "\n",
    "## The model has pretrained Tensorflow weights (check that the file tf_model.h5 exists)\n",
    "  - bert-base-multilingual-uncased (.h5 file exists)\n",
    "  - xlm-roberta-base (.h5 file exists)\n",
    "  - google/muril-large-cased (.h5 is not exsist but we can get it from pytorch_model.bin)\n",
    "\n",
    "## The model uses the default tokenizer (config.json should not contain a custom tokenizer_class setting)\n",
    "  - bert-base-multilingual-uncased (does not have any custom tokenizer)\n",
    "  - xlm-roberta-base (does not have any custom tokenizer)\n",
    "  - google/muril-large-cased (does not have any custom tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAudFmIGI8WO"
   },
   "outputs": [],
   "source": [
    "!pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxuMz0iDI9Nl"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html /content/Compare_Multilingual_Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GE_wpOeJKXq"
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-oeXiRyNtXI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
